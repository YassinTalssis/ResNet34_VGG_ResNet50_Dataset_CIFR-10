{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Yassin TAlssis\n%matplotlib inline\nfrom PIL import Image\nfrom keras.datasets import cifar10\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport timeit\n\ndevice_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load dataset\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n# summarize loaded dataset\nprint(f'Train: X= {x_train.shape}, y= {y_train.shape}')\nprint(f'Test: X={x_test.shape}, y={y_test.shape}')\nprint(\"Some of the Images in the Dataset are displayed below\")\n\nfigure = plt.figure(figsize=(12,12))\nfor i in range(12, 21):\n# define subplot\n    plt.subplot(3,3,i-11)\n# plot raw pixel data\n    plt.xlabel(y_train[i])\n    plt.imshow(x_train[i])\n# show the figure\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.dtype, x_test.dtype)\n# Normalizing data \n# As the Data is of type uint8 we will convert it to Float\nx_train = x_train.astype(float)\nx_test = x_test.astype(float)\nx_train = x_train/255.0\nx_test = x_test/255.0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_results(history):\n    figure = plt.figure(figsize=(15, 10))\n    plt.subplot(211)\n    plt.title('Cross Entropy Loss')\n    plt.plot(history.history['loss'], color='blue', label='train')\n    plt.plot(history.history['val_loss'], color='orange', label='test')\n    # plot accuracy\n    plt.subplot(212)\n    plt.title('Classification Accuracy')\n    plt.plot(history.history['accuracy'], color='blue', label='train')\n    plt.plot(history.history['val_accuracy'], color='orange', label='test')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ResNet34","metadata":{}},{"cell_type":"code","source":"def convolutional_block(x, filter):\n    \n    # copy tensor to variable called x_skip\n    x_skip = x\n    \n    # Layer 1\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    \n    # Layer 2\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    \n    # Processing Residue with conv(1,1)\n    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n    \n    # Add Residue\n    x = tf.keras.layers.Add()([x, x_skip])     \n    x = tf.keras.layers.Activation('relu')(x)\n    \n    return x\n\ndef identity_block(x, filter):\n    \n    # copy tensor to variable called x_skip\n    x_skip = x\n    \n    # Layer 1\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    \n    # Layer 2\n    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n    \n    # Add Residue\n    x = tf.keras.layers.Add()([x, x_skip])     \n    x = tf.keras.layers.Activation('relu')(x)\n    \n    return x\ndef ResNet34(shape = (32, 32, 3), classes = 10):\n  \n    # Step 1 (Setup Input Layer)\n    x_input = tf.keras.layers.Input(shape)\n    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n    \n    # Step 2 (Initial Conv layer along with maxPool)\n    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n    \n    # Define size of sub-blocks and initial filter size\n    block_layers = [3, 4, 6, 3]\n    filter_size = 64\n    \n    # Step 3 Add the Resnet Blocks\n    for i in range(4):\n        if i == 0:\n            # For sub-block 1 Residual/Convolutional block not needed\n            for j in range(block_layers[i]):\n                x = identity_block(x, filter_size)\n        else:\n            # One Residual/Convolutional Block followed by Identity blocks\n            filter_size = filter_size*2\n            x = convolutional_block(x, filter_size)\n            for j in range(block_layers[i] - 1):\n                x = identity_block(x, filter_size)\n          \n    # Step 4 End Dense Network\n    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n    \n    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n    return model\n\nmodel = ResNet34()\nmodel.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs = 15)\nvisualize_results(history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VGG","metadata":{}},{"cell_type":"code","source":"# VGG Based Architechture (No residual Blocks)\n\"\"\"\nArchitecture:\n\nBlock Architecture:\nConv2D\nBatch Normalization\nCanv2D\nBatch Normalization\nMaxPool\nDropout\n\nStack Blocks\nFully Connected Dense Layers\nOutput Layer\n\"\"\"\ndef model_training():\n    class MyCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy') >= 0.96):\n                print(\"The model has reached 96% train accuracy !\")\n                self.model.stop_training = True\n\n    callback = MyCallback()\n\n    model = tf.keras.models.Sequential([\n      # BLOCK-1\n          tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape=(32,32,3), padding = 'same'),\n          tf.keras.layers.BatchNormalization(),\n          tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape=(32,32,3), padding = 'same'),\n          tf.keras.layers.BatchNormalization(),\n          tf.keras.layers.MaxPool2D((2,2)),\n          tf.keras.layers.Dropout(0.2),\n      # BLOCK-2\n          tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', input_shape=(32,32,3), padding = 'same'),\n          tf.keras.layers.BatchNormalization(),\n          tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', input_shape=(32,32,3), padding = 'same'),\n          tf.keras.layers.BatchNormalization(),\n          tf.keras.layers.MaxPool2D((2,2)), \n          tf.keras.layers.Dropout(0.3),\n      # BLOCK-3    \n          tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', input_shape=(32,32,3), padding = 'same'),\n          tf.keras.layers.BatchNormalization(), \n          tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', input_shape=(32,32,3), padding = 'same'),\n          tf.keras.layers.BatchNormalization(),\n          tf.keras.layers.MaxPool2D((2,2)),\n          tf.keras.layers.Dropout(0.4),\n      # BLOCK-4\n          tf.keras.layers.Conv2D(256, (3,3), activation = 'relu', input_shape=(32,32,3), padding = 'same'),\n          tf.keras.layers.BatchNormalization(),\n          tf.keras.layers.Conv2D(256, (3,3), activation = 'relu', input_shape=(32,32,3), padding = 'same'),\n          tf.keras.layers.BatchNormalization(),\n          tf.keras.layers.MaxPool2D((2,2)),\n          tf.keras.layers.Dropout(0.4),\n      # End BLOCK-(FC Dense with BN and Activation = RELU)\n          tf.keras.layers.Flatten(),\n          tf.keras.layers.Dense(512, activation = 'relu'),\n          tf.keras.layers.BatchNormalization(),\n          tf.keras.layers.Dropout(0.5),\n          tf.keras.layers.Dense(256, activation = 'relu'),\n          tf.keras.layers.BatchNormalization(),\n          tf.keras.layers.Dropout(0.7),\n          tf.keras.layers.Dense(128, activation = 'relu'),\n          tf.keras.layers.BatchNormalization(),\n          tf.keras.layers.Dropout(0.7),\n          tf.keras.layers.Dense(10, activation='softmax')\n  ])\n\n    model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n\n    print(model.summary())\n\n    return model, callback","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Augmentation can also be applied to further improve the accuracy \n\"\"\"\ndatagen = tf.keras.preprocessing.images.ImageDataGeterator(rotation_range=0,\n    width_shift_range=1.0,\n    height_shift_range=1.0,\n    horzontal_flip = True)\naug_data = datagen.flow(x_train, x_test)\nhistory = model.fit(aug_data, validation_data=(x_test, y_test), epochs = 150, callbacks=[callback])\nvisualize_results(history)\n\"\"\"\n# But due to Limited Resources Training the Model with Augmented Data was not possible \n# Platforms -(Google Colab and Kaggle Kernel (GPU Acceleration))\nmodel1, callback = model_training()\nhistory = model1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs = 150, callbacks=[callback])\nvisualize_results(history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport random\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\n# Let's define a new Model that will take an image as input, and will output\n# intermediate representations for all layers in the previous model after\n# the first.\nsuccessive_outputs = [layer.output for layer in model1.layers[1:]]\n\nvisualization_model = tf.keras.models.Model(inputs = model1.input, outputs = successive_outputs)\n\n\nx = img_to_array(x_train[19])  # Numpy array with shape (32, 32, 3)\nx = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 32, 32, 3)\n\nx /= 255\n\nplt.imshow(x_train[19])\npred = list(model2.predict(x)[0])\nprint(pred)\nprint(max(pred))\nclasses = pred.index(max(pred))\nprint(\"Prediction :\", classes)\n\nsuccessive_feature_maps = visualization_model.predict(x)\n\nlayer_names = [layer.name for layer in model1.layers[1:]]\n\nfor layer_name, feature_map in zip(layer_names, successive_feature_maps):\n  # print(feature_map.shape)\n  if len(feature_map.shape) == 4:\n    # for the conv / maxpool layers, not the fully-connected layers\n    n_features = feature_map.shape[-1]  # number of features in feature map\n    # The feature map has shape (1, size, size, n_features)\n    size = feature_map.shape[1]\n    # We will tile our images in this matrix\n    display_grid = np.zeros((size, size * n_features))\n    for i in range(n_features):\n        # Postprocess the feature to make it visually palatable\n        x = feature_map[0, :, :, i]\n        x -= x.mean()\n        x /= x.std()\n        x *= 64\n        x += 128\n        x = np.clip(x, 0, 255).astype('uint8')\n        # We'll tile each filter into this big horizontal grid\n        display_grid[:, i * size : (i + 1) * size] = x\n    # Display the grid\n    scale = 20. / n_features\n    plt.figure(figsize=(scale * n_features, scale))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto', cmap='viridis')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In reference to SOTA Accuracy (Transfer Learning with ResNet50)\n# Transfer Learning Approach using Resnet 50 Pretrained on Imagenet\n\ndef resnet():\n        base_model = tf.keras.applications.ResNet50V2(\n        include_top=False,\n        weights='imagenet',\n        input_shape=(32, 32, 3)\n        )\n\n        headModel = base_model.output\n        headModel = tf.keras.layers.GlobalAveragePooling2D()(headModel)\n        headModel = tf.keras.layers.Flatten()(headModel)\n        headModel = tf.keras.layers.Dense(512, activation=\"relu\")(headModel)\n        headModel = tf.keras.layers.Dropout(0.7)(headModel)\n        headModel = tf.keras.layers.Dense(10, activation=\"softmax\")(headModel)\n\n        model = tf.keras.models.Model(inputs = base_model.input, outputs = headModel)\n\n\n        model.compile(optimizer = tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n        print(model.summary())\n        return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_callbacks = [\n    tf.keras.callbacks.EarlyStopping(\n        monitor=\"val_loss\", patience=10,\n        restore_best_weights=True\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=\"val_loss\", factor=0.5,\n        patience=3, verbose=1\n    )\n]\nmodel2 = resnet()\nhistory = model2.fit(x_train, y_train, steps_per_epoch = 781, \n                     validation_data=(x_test, y_test), epochs = 100, callbacks=train_callbacks)\nvisualize_results(history)","metadata":{},"execution_count":null,"outputs":[]}]}